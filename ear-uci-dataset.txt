*---------------------------------------*
| EAR-UCI Dataset                       |
| 2020-2021                             |
| Jigar Hira, Tritai Nguyen, Ian Flores |
| University of California, Irvine      |
|                                       |
| Version 3.0                           |
*---------------------------------------*


Audio dataset used to train the audio classification model used in the EAR-UCI project.


This dataset is comprised of audio samples from the following public datasets:
    FSD50K          (glass break, scream, other)
    UrbanSound8K    (gunshot)


All sound samples are in ./audio and spectrograms generated from the samples are found in ./spectrograms


There are four sample categories:

    [Name]          |  [ID] |
    ----------------|-------|
    Other           |   0   |
    Glass Breaking  |   1   |
    Gunshot         |   2   |
    Screaming       |   3   |
   

Note: The "Other" samples were randomly selected audio samples from any of the other categories in the FSD50K dataset.


Dataset has 1000 unique samples split into a training set and a validation set.
    Training set contains 900 unique samples (225 samples per category).
    Validation set contains 100 unique samples (25 samples per category).


Each unique sample is then augmented in two ways in the following order:
    1.  A random time offset (between 0 and 2 seconds)
    2.  Mixing the sample with a random standard deviation (between 0.01 and 0.05) gaussian noise
4 random time offsets are generated.
4 random standard deviation gaussian noise signals are applied to each time offset
Each unique sample provides 16 augmented samples.

After augmentaion the dataset has a total of 16000 samples.

Each sample is named as follows: {sample_id}-{category_id}-{set_type}-{offset_augment}-{noise_augment}.wav
    {sample_id}:        Overall audio sample number. Sample ID is unique to each sound file.
    {category_id}:      Number which corresponds to one of the four categories.
    {set_type}:         Train or validation set, 0 for training set and 1 for validation set.
    {offset_augment}:   Ranges from 0 to 3. Represents a random time offset augmentaion.
    {noise_augment}:    Ranges from 0 to 3. Represents a random standard deviation gaussian noise augmentation applied after the offset augmentation.
